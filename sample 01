import pandas as pd

# File paths
input_filepath = r"C:\Downloads\test\your_input_filename.csv"  # Change to your actual file name
output_filepath = r"C:\Downloads\test\output.csv"

# Read CSV
df = pd.read_csv(input_filepath, dtype={'Id': str})

# Compute normalized names for each row
def make_normalized(row):
    return ' '.join(sorted([row['Fname'], row['Lname']]))

df['normalized_name'] = df.apply(make_normalized, axis=1)

# Count duplicates of each normalized_name among Name column
df['is_group'] = df.groupby('normalized_name')['Name'].transform('count')

# Assign 'match' to all rows in groups of size 2+ where Name equals normalized_name
df['Status'] = df.apply(lambda row: 'match' if df[(df['normalized_name'] == row['normalized_name'])].shape[0] > 1 else '', axis=1)

# Optional: sort/order/group as you prefer
df_sorted = df.sort_values(['normalized_name', 'Id'])

# Drop helper columns
df_sorted = df_sorted.drop(columns=['normalized_name', 'is_group'])

# Save
df_sorted.to_csv(output_filepath, index=False)
print(f"Output written to: {output_filepath}")
